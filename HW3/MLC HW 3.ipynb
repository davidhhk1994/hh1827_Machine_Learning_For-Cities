{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (15 points) \n",
    "\n",
    "#### This question is to be solved by hand.\n",
    "\n",
    "Given the following learned Bayesian network structure explaining the relationships between variables in container shipping data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('HW3Q1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Which of the following conditional independence relationships hold? Choose “Independent” or “Dependent” for each (6 points):\n",
    "\n",
    "CI (Shipper Name, Value | F Port)?\n",
    "\n",
    "CI (Shipper Name, Value | Shipping Line)? \n",
    "\n",
    "CI (Foreign Port, Commodity | Country)? \n",
    "\n",
    "CI (Foreign Port, Commodity | County, Weight)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Now consider a smaller dataset with only four discrete attributes (Shipping Line, US Port, Foreign Port, Weight), and the following conditional probability distributions:\n",
    "\n",
    "Shipping Line: CSCO (70%), ASCO (30%)\n",
    "\n",
    "Foreign Port | Shipping Line = CSCO: Yokohama (40%), Vancouver (60%)\n",
    "\n",
    "Foreign Port | Shipping Line = ASCO: Vancouver (100%)\n",
    "\n",
    "US Port | Shipping Line = ASCO: Seattle (100%)\n",
    "\n",
    "US Port | Shipping Line = CSCO: Seattle (80%), Los Angeles (20%)\n",
    "\n",
    "Weight | Shipping Line = ASCO, Foreign Port = Vancouver: Light (30%), Medium (50%), Heavy (20%)\n",
    "\n",
    "Weight | Shipping Line = CSCO, Foreign Port = Vancouver: Light (15%), Medium (70%), Heavy (15%)\n",
    "\n",
    "Weight | Shipping Line = CSCO, Foreign Port = Yokohama: Light (10%), Medium (30%), Heavy (60%)\n",
    "\n",
    "Which of the following packages is most anomalous?\n",
    "\n",
    "a) A heavy package shipped from Vancouver to Seattle by ASCO\n",
    "\n",
    "b) A heavy package shipped from Vancouver to Seattle by CSCO\n",
    "\n",
    "c) A heavy package shipped from Yokohama to Los Angeles by CSCO\n",
    "\n",
    "To answer this question, compute the likelihood of each package given the Bayesian Network (lowest likelihood = most anomalous). You must show your calculations to receive credit. (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Your answers here, including all calculations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Bayesian Network Learning (35 points)\n",
    "\n",
    "In this question, we use dataset: \"HW3Q2.csv\" for Bayesian Network Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data2=pd.read_csv(\"HW3Q2.csv\")\n",
    "train,test=train_test_split(data2,random_state=9,test_size=0.4)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Use the training data to select the best structure you want to use for Bayesian Network Learning. Please use Hill Climbing with BIC score metric. (10 points)\n",
    "\n",
    "b) Use the Bayesian Estimator to estimate the CPDs for your model and visualize the network with CPDs. (15 points)\n",
    "\n",
    "c) Use the model to predict \"A\" for the testing dataset. Report the out-of-sample prediction accuracy. (10 points)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Clustering: Spatial and Temporal Distributions of Chicago Crimes (50 points)\n",
    "\n",
    "In this question you will use k-means and Gaussian mixture clustering in sklearn and hierarchical clustering in scipy to answer the question, “Do different types of crime display different trends over space and time?”  The dataset “HW3Q3_1.csv” consists of data for 119 different types of crime, each of which occurred at least 100 times in Chicago during the year 2016.  For each crime type, we have various features representing the spatial and temporal distribution of crime, including:\n",
    "\n",
    "- The proportion of all crimes of that type that occurred on each day of the week (day_Sun, day_Mon, …, day_Sat).\n",
    "\n",
    "- The proportion of all crimes of that type that occurred on each hour of the day (hour_0 = midnight to 12:59am, hour_1 = 1am to 1:59am, …, hour_23 = 11pm to 11:59pm).\n",
    "\n",
    "- The proportion of all crime of that type that occurred in each of the 77 community areas of Chicago (community_area_1 … community_area_77).\n",
    "\n",
    "We also have, for each crime type, its categorization by the FBI:\n",
    "\n",
    "- Category = “P1V” corresponds to Part 1 Violent Crime, i.e., serious violent crimes\n",
    "\n",
    "- Category = “P1P” corresponds to Part 1 Property Crime, i.e., serious property crimes\n",
    "\n",
    "- Category = “P2” corresponds to Part 2 (less serious) crimes.\n",
    "\n",
    "To answer parts a through f, you should cluster the 119 crime types using k-means into k = 3 clusters using only the hour of day (hour_0..hour_23) attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Copy each cluster’s mean values for hour_0…hour_23 into a DataFrame and create a line graph to visualize these values by cluster.  (5 pts)\n",
    "\n",
    "b) Describe the three different hour-of-day trends represented by these three clusters (5 pts).\n",
    "\n",
    "c) Do you notice any consistent trends about which crime types are assigned to which cluster?  Note that by a \"crime type\", we are referring to specific crimes such as \"narcotics\" or \"assault\", not the FBI categories. (5 pts)  \n",
    "\n",
    "d) Do the three clusters have different day-of-week trends?  Again, visualize the trends for each cluster by creating a line graph and discuss any notable differences.  (5 pts)\n",
    "\n",
    "e) Do the three clusters affect different types of communities/neighborhoods?  To answer this question, you could first compute the proportions of \"cluster 1\", \"cluster 2\", and \"cluster 3\" crimes for each community area, and identify particular community areas with disproportionate amounts of a given cluster.  You can then use the provided file (HW3Q3_2.csv), to determine whether these community areas have any notable common characteristics (poverty, overcrowding, etc.).  You may also wish to consult the Chicago Community Areas map at https://en.wikipedia.org/wiki/Community_areas_in_Chicago. (5 pts)\n",
    "\n",
    "f) How well do the three groups formed by clustering hour-of-day trends correspond to the FBI’s division between P1V, P1P, and P2 crimes? (5 pts)\n",
    "\n",
    "g) For part g, you will use the same dataset to compare the clusters produced by several different methods.  But this time you should cluster using only the _day-of-week_ (not hour-of-day) attributes (day_Sun..day_Sat).  Please perform four different clusterings using (i) k-means, (ii) Gaussian mixture models, (iii) Bottom-up hierarchical clustering with \"single link\" distance metric, and (iv) Bottom-up hierarchical clustering with \"complete link\" distance metric.  In each case, you should choose the number of clusters using the silhouette method (or another established method of your choice- please specify).  For each clustering, report the number of clusters formed and the number of elements in each cluster. You should also identify any notable similarities or differences between the clusterings. (20 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=pd.read_csv(\"HW3Q3_1.csv\")\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=pd.read_csv(\"HW3Q3_2.csv\")\n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
